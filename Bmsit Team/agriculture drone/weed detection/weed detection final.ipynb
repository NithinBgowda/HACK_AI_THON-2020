{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../agricultural drone/Train/'\n",
    "test_path =  '../agricultural drone/Test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = (224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
    "\n",
    "train_data = train_generator.flow_from_directory(train_path,\n",
    "                                                 target_size=(224, 224),\n",
    "                                                 color_mode=\"rgb\",\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 shuffle=True,\n",
    "                                                 subset='training')\n",
    "\n",
    "val_data = train_generator.flow_from_directory(train_path,\n",
    "                                                 target_size=(224, 224),\n",
    "                                                 color_mode=\"rgb\",\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 shuffle=False,\n",
    "                                                 subset='validation')\n",
    "\n",
    "test_generator  = ImageDataGenerator(rescale=1./255)\n",
    "test_data = test_generator.flow_from_directory(test_path,\n",
    "                                                 target_size=(224, 224),\n",
    "                                                 color_mode=\"rgb\",\n",
    "                                                 class_mode=\"categorical\",shuffle=False,\n",
    "                                                 batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense,Flatten,Input,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
    "    input_tensor=Input(shape=IMAGE_SIZE))\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(4096, activation='relu')(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(4096, activation='relu')(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(3, activation='softmax')(headModel)\n",
    "\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=2,monitor='val_loss')\n",
    "results = model.fit_generator(train_data,epochs=5,\n",
    "                              validation_data=val_data,\n",
    "                             callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.history.history)[['accuracy','val_accuracy']].plot()\n",
    "pd.DataFrame(model.history.history)[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict_generator(test_data)\n",
    "pred_class = [np.argmax(x) for x in test_pred]\n",
    "test_data.class_indices\n",
    "true_class = test_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(true_class,pred_class))\n",
    "sns.heatmap(confusion_matrix(true_class,pred_class),annot=True)\n",
    "mapping_class = test_data.class_indices\n",
    "mapping_class = dict([(value, key) for key, value in mapping_class.items()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_data))\n",
    "images = images.reshape(64, 224,224,3)\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16,16))\n",
    "\n",
    "for ax, img, label in zip(axes.flat, images[:16], labels[:16]):\n",
    "    ax.imshow(img)\n",
    "    true_label = mapping_class[np.argmax(label)]\n",
    "    \n",
    "    pred_prob = model.predict(img.reshape(1, 224,224, 3))\n",
    "    pred_label = mapping_class[np.argmax(pred_prob)]\n",
    "    \n",
    "    prob_class = np.max(pred_prob) * 100\n",
    "    \n",
    "    ax.set_title(f\"TRUE LABEL: {true_label}\", fontweight = \"bold\", fontsize = 12)\n",
    "    ax.set_xlabel(f\"PREDICTED LABEL: {pred_label}\\nProb({pred_label}) = {(prob_class):.2f}%\",\n",
    "                 fontweight = \"bold\", fontsize = 10,\n",
    "                 color = \"blue\" if true_label == pred_label else \"red\")\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "plt.tight_layout()\n",
    "fig.suptitle(\"PREDICTION for 16 RANDOM TEST IMAGES\", size = 30, y = 1.03, fontweight = \"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_data))\n",
    "images = images.reshape(64, 224,224,3)\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16,16))\n",
    "\n",
    "for ax, img, label in zip(axes.flat, images[:16], labels[:16]):\n",
    "    ax.imshow(img)\n",
    "    true_label = mapping_class[np.argmax(label)]\n",
    "    \n",
    "    pred_prob = model.predict(img.reshape(1, 224,224, 3))\n",
    "    pred_label = mapping_class[np.argmax(pred_prob)]\n",
    "    \n",
    "    prob_class = np.max(pred_prob) * 100\n",
    "    \n",
    "    ax.set_title(f\"TRUE LABEL: {true_label}\", fontweight = \"bold\", fontsize = 12)\n",
    "    ax.set_xlabel(f\"PREDICTED LABEL: {pred_label}\\nProb({pred_label}) = {(prob_class):.2f}%\",\n",
    "                 fontweight = \"bold\", fontsize = 10,\n",
    "                 color = \"blue\" if true_label == pred_label else \"red\")\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "plt.tight_layout()\n",
    "fig.suptitle(\"PREDICTION for 16 RANDOM TEST IMAGES\", size = 30, y = 1.03, fontweight = \"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weed_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_json,'r') as train:\n",
    "    train_region = json.load(train)\n",
    "with open(test_json,'r') as test:\n",
    "    test_region = json.load(test)\n",
    "train_images_list = list(train_region.keys())\n",
    "test_images_list = list(test_region.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(label_csv)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_last_2FC = tf.keras.models.Model(model.inputs,model.layers[-5].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = []\n",
    "\n",
    "test_features = []\n",
    "\n",
    "\n",
    "for index in tqdm(range(len(labels))):\n",
    "    id = labels.loc[index,'filename']\n",
    "    img = cv2.imread(images_path + id)\n",
    "    rgb_img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    xmin,ymin,xmax,ymax = int(labels.loc[index,'xmin']) ,int(labels.loc[index,'ymin']),int(labels.loc[index,'xmax']),int(labels.loc[index,'ymax'])\n",
    "\n",
    "    resized = cv2.resize(rgb_img[ymin:ymax,xmin:xmax,:],(224,224))\n",
    "\n",
    "    feature_of_img = model_without_last_2FC.predict(resized.reshape(1,224,224,3)/255)\n",
    "    \n",
    "    if id in train_images_list:\n",
    "        \n",
    "        train_features.append([feature_of_img,labels.loc[index,'class']])\n",
    "        \n",
    "    else:\n",
    "        test_features.append([feature_of_img,labels.loc[index,'class']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,img in tqdm(enumerate(os.listdir(negative_ex_path)[:5000])):  #only extracting for 10,000 images\n",
    "    img = cv2.imread(negative_ex_path +img  )\n",
    "    img = img.astype('uint8')\n",
    "    rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    #images already in (224,224,3)\n",
    "    feature_of_img = model_without_last_2FC.predict(rgb.reshape(1,224,224,3)/255)\n",
    "    if index<3500:\n",
    "        train_features.append([feature_of_img,'background'])\n",
    "    else:\n",
    "        test_features.append([feature_of_img,'background'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(train_features)\n",
    "X_train = np.array([x[0] for x in train_features])\n",
    "X_train = X_train.reshape(-1,4096)\n",
    "y_train = [x[1] for x in train_features]\n",
    "y_train = np.array(y_train).reshape(-1,1)\n",
    "X_test = np.array([x[0] for x in test_features])\n",
    "X_test = X_test.reshape(-1,4096)\n",
    "y_test = [x[1] for x in test_features]\n",
    "y_test = np.array(y_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_linear = SVC(kernel = 'linear', C = 1,probability=True).fit(X_train, y_train) \n",
    "svm_predictions = svm_model_linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = svm_model_linear.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(y_test, svm_predictions) \n",
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(negative_ex_path + os.listdir(negative_ex_path)[45] )\n",
    "rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_of_img = model_without_last_2FC.predict(rgb.reshape(1,224,224,3)/255)\n",
    "svm_model_linear.predict(feature_of_img)\n",
    "svm_model_linear.predict_proba(feature_of_img)\n",
    "svm_model_linear.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(images_path+'agri_0_1024.jpeg')\n",
    "rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(rgb)\n",
    "resized = cv2.resize(rgb,(224,224))\n",
    "plt.imshow(resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_linear.predict_proba(model_without_last_2FC.predict(resized.reshape(1,224,224,3)/255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('svm_classifier.pkl','wb') as svm_model:\n",
    "    pickle.dump(svm_model_linear , svm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import warnings\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../agricultural drone/RCNN_crop_weed_classification_model.h5'\n",
    "test_img_path = '../agricultural drone/Test'\n",
    "images_path = '../agricultural drone/agri_data/data/'\n",
    "svm_model_path = '../agricultural drone/svm_classifier.pkl'\n",
    "images_name = [x for x in os.listdir(images_path) if x.endswith('.jpeg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_path)\n",
    "model.summary()\n",
    "model_without_last_two_fc = tf.keras.models.Model(model.inputs,model.layers[-5].output)\n",
    "model_without_last_two_fc.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(svm_model_path,'rb') as svm:\n",
    "    svm_model = pickle.load(svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_calc(bb1 , bb2):\n",
    "  \n",
    "    true_xmin, true_ymin, true_width, true_height  = bb1\n",
    "    bb_xmin, bb_ymin,  bb_width, bb_height = bb2\n",
    "\n",
    "    true_xmax = true_xmin + true_width\n",
    "    true_ymax = true_ymin + true_height\n",
    "    bb_xmax = bb_xmin + bb_width\n",
    "    bb_ymax = bb_ymin + bb_height\n",
    "\n",
    "    #calculating area\n",
    "    true_area = true_width * true_height\n",
    "    bb_area   = bb_width * bb_height \n",
    "\n",
    "    #calculating itersection cordinates\n",
    "    inter_xmin = max(true_xmin , bb_xmin) \n",
    "    inter_ymin = max(true_ymin , bb_ymin)\n",
    "    inter_xmax = min(true_xmax , bb_xmax)\n",
    "    inter_ymax = min(true_ymax , bb_ymax)\n",
    "\n",
    "    if inter_xmax <= inter_xmin or inter_ymax <= inter_ymin:\n",
    "        iou = 0\n",
    "\n",
    "\n",
    "    else:\n",
    "        inter_area = (inter_xmax - inter_xmin) * (inter_ymax - inter_ymin)\n",
    "\n",
    "\n",
    "        iou = inter_area / (true_area + bb_area - inter_area)\n",
    "        \n",
    "    assert iou<=1\n",
    "    assert iou>=0\n",
    "    \n",
    "    return iou\n",
    "\n",
    "def detection(images_path,confidence=0.9,iou_thresh=0.1):\n",
    "    \n",
    "    # appling selective search\n",
    "    img = plt.imread(images_path)\n",
    "    cv2.setUseOptimized(True);\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    ss.setBaseImage(img)\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "    rects = ss.process()\n",
    "    sel_rects = rects[:2000]\n",
    "    \n",
    "    pred_crop=[]\n",
    "    pred_weed=[]\n",
    "    for index, rect in tqdm(enumerate(sel_rects)):\n",
    "\n",
    "        x,y,w,h = rect\n",
    "        roi = img[y:y+h,x:x+w,:]\n",
    "        resized_roi = cv2.resize(roi,(224,224))/255\n",
    "        \n",
    "        # Feature extraction\n",
    "        \n",
    "        feature = model_without_last_two_fc.predict(resized_roi.reshape(-1,224,224,3))\n",
    "        \n",
    "        # SVM prediction\n",
    "        pred = svm_model.predict_proba(feature.reshape(-1,4096))\n",
    "        pred_lab=svm_model.predict(feature.reshape(-1,4096))\n",
    "\n",
    "        if pred_lab == 'crop' and np.max(pred)>confidence:\n",
    "            pred_crop.append([list(rect),np.max(pred)])\n",
    "        elif pred_lab=='weed' and np.max(pred)>confidence:\n",
    "            pred_weed.append([list(rect),np.max(pred)])\n",
    "            \n",
    "    final = []\n",
    "    \n",
    "    # Detection for crop class\n",
    "    if len(pred_crop) != 0:\n",
    "        pred_score_crop = [x[1] for x in pred_crop]\n",
    "        pred_bb_crop = [x[0] for x in pred_crop]\n",
    "\n",
    "        for i in range(len(pred_crop)):\n",
    "            temp_bb , temp_score = pred_bb_crop.copy() , pred_score_crop.copy()\n",
    "            if len(temp_bb) !=0:\n",
    "\n",
    "                max_score_box = temp_bb[np.argmax(temp_score)]\n",
    "\n",
    "                if [max_score_box,np.max(temp_score)] not in final:\n",
    "                    final.append([max_score_box,np.max(temp_score),'crop'])\n",
    "                    index_should_del = []\n",
    "\n",
    "                    for ind,other_bb in enumerate(temp_bb):\n",
    "                        iou_score = iou_calc(max_score_box , other_bb)\n",
    "                        \n",
    "                        # Non maximum suppression(nms)\n",
    "                        \n",
    "                        if iou_score >= iou_thresh:\n",
    "                            index_should_del.append(ind)\n",
    "\n",
    "                    pred_bb_crop    = []\n",
    "                    pred_score_crop = []\n",
    "                    for bb_index ,bb_value in enumerate(temp_bb) :\n",
    "                        if bb_index not in index_should_del:\n",
    "                            pred_bb_crop.append(bb_value)\n",
    "\n",
    "                    for score_index ,score_value in enumerate(temp_score) :\n",
    "                        if score_index not in index_should_del:\n",
    "                            pred_score_crop.append(score_value)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # Detection for weed class\n",
    "\n",
    "    if len(pred_weed) != 0:\n",
    "        pred_score_weed = [x[1] for x in pred_weed]\n",
    "        pred_bb_weed = [x[0] for x in pred_weed]\n",
    "\n",
    "        for i in range(len(pred_weed)):\n",
    "            temp_bb , temp_score = pred_bb_weed.copy() , pred_score_weed.copy()\n",
    "            if len(temp_bb) !=0:\n",
    "\n",
    "                max_score_box = temp_bb[np.argmax(temp_score)]\n",
    "\n",
    "                if [max_score_box,np.max(temp_score)] not in final:\n",
    "                    final.append([max_score_box,np.max(temp_score),'weed'])\n",
    "                    index_should_del = []\n",
    "\n",
    "                    for ind,other_bb in enumerate(temp_bb):\n",
    "                        iou_score = iou_calc(max_score_box , other_bb)\n",
    "\n",
    "                        if iou_score >= iou_thresh:\n",
    "                            index_should_del.append(ind)\n",
    "\n",
    "                    pred_bb_weed    = []\n",
    "                    pred_score_weed = []\n",
    "                    for bb_index ,bb_value in enumerate(temp_bb) :\n",
    "                        if bb_index not in index_should_del:\n",
    "                            pred_bb_weed.append(bb_value)\n",
    "\n",
    "                    for score_index ,score_value in enumerate(temp_score) :\n",
    "                        if score_index not in index_should_del:\n",
    "                            pred_score_weed.append(score_value)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "   \n",
    "    imOut = img.copy()\n",
    "    for rect,score,cls in final:\n",
    "        \n",
    "        x,y,w,h = rect\n",
    "        if cls == 'weed':\n",
    "            color =(255,0,0)\n",
    "        if cls == 'crop':\n",
    "            color = (0,255,0)\n",
    "\n",
    "        cv2.rectangle(imOut,(x,y),(x+w,y+h),color,2)\n",
    "\n",
    "        cv2.putText(imOut,cls+':'+str(round(score*100,2)),(x,y-8),cv2.FONT_HERSHEY_SIMPLEX,1, color, 2, cv2.LINE_AA)\n",
    "    plt.imshow(imOut)\n",
    "    cv2.imwrite('prediction.jpeg',imOut)\n",
    "   \n",
    "\n",
    "    return final \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection(images_path+images_name[500])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
